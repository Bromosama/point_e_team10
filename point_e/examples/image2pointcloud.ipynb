{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import nopdb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.util.plotting import plot_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating base model...\n",
      "creating upsample model...\n",
      "downloading base checkpoint...\n",
      "downloading upsampler checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('creating base model...')\n",
    "base_name = 'base40M' # use base300M or base1B for better results\n",
    "base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
    "base_model.eval()\n",
    "base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
    "\n",
    "print('creating upsample model...')\n",
    "upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "upsampler_model.eval()\n",
    "upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "\n",
    "print('downloading base checkpoint...')\n",
    "base_model.load_state_dict(load_checkpoint(base_name, device))\n",
    "\n",
    "print('downloading upsampler checkpoint...')\n",
    "upsampler_model.load_state_dict(load_checkpoint('upsample', device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointCloudSampler(\n",
    "    device=device,\n",
    "    models=[base_model, upsampler_model],\n",
    "    diffusions=[base_diffusion, upsampler_diffusion],\n",
    "    num_points=[1024, 4096 - 1024],\n",
    "    aux_channels=['R', 'G', 'B'],\n",
    "    guidance_scale=[3.0, 3.0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16e2294c688403caf46c9e0f9f19d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load an image to condition on.\n",
    "img = Image.open('example_data/cube_stack.jpg')\n",
    "\n",
    "# Produce a sample from the model.\n",
    "samples = None\n",
    "with nopdb.capture_calls(base_model.backbone.resblocks[-1].attn.attention.forward) as attn_call:\n",
    "    for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(images=[img]))):\n",
    "        samples = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_heads_to_batch_dim(tensor):\n",
    "        batch_size, seq_len, heads, dim = tensor.shape\n",
    "        tensor = tensor.permute(0, 2, 1, 3).reshape(batch_size * heads, seq_len, dim)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "dict_keys(['self', 'qkv', 'bs', 'n_ctx', 'width', 'attn_ch', 'scale', 'q', 'k', 'v', 'weight', 'wdtype'])\n",
      "torch.Size([2, 1281, 8, 64])\n",
      "torch.Size([2, 1281, 8, 64])\n",
      "torch.Size([16, 1281, 64])\n",
      "torch.Size([16, 1281, 64])\n"
     ]
    }
   ],
   "source": [
    "print(len(attn_call))\n",
    "print(attn_call[0].locals.keys())\n",
    "# print(attn_call[0].locals['weight'].shape)\n",
    "# print(attn_call.locals['x'].shape)\n",
    "\n",
    "# attentions = attn_call[0].locals['weight'][0, :, 0, 257:].reshape(8, -1)\n",
    "# print(attentions.shape)\n",
    "# print(attn_call[0].locals['qkv'].shape)\n",
    "\n",
    "print(attn_call[0].locals['q'].shape)\n",
    "print(attn_call[0].locals['k'].shape)\n",
    "new_q = reshape_heads_to_batch_dim(attn_call[0].locals['q'])\n",
    "new_k = reshape_heads_to_batch_dim(attn_call[0].locals['k'])\n",
    "\n",
    "print(new_q.shape)\n",
    "print(new_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1281, 1281])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import math\n",
    "scale = 1 / math.sqrt(math.sqrt(attn_call[0].locals['attn_ch']))\n",
    "\n",
    "#Manually extract the query and key tensors and combine them as in transformer module, to obtain the attention map.\n",
    "new_q = reshape_heads_to_batch_dim(attn_call[0].locals['q'])\n",
    "new_k = reshape_heads_to_batch_dim(attn_call[0].locals['k'])\n",
    "attention_scores = torch.einsum(\"b i d, b j d -> b i j\", new_q, new_k) * scale\n",
    "\n",
    "attention_probs = attention_scores.softmax(dim=-1)\n",
    "print(attention_probs.shape)\n",
    "''' \n",
    "Shape is batch*heads, 1281,1281. Now perhaps we can slice the 1st dimension starting \n",
    "after all the extra tokens to get the attentions of the point cloud. So smth like\n",
    "[:,257:,258:] will give the attention of all points that the first point attends to.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4038ef9cff2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_to_point_clouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_point_cloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampler' is not defined"
     ]
    }
   ],
   "source": [
    "pc = sampler.output_to_point_clouds(samples)[0]\n",
    "fig = plot_point_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('3.9.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b270b0f43bc427bcab7703c037711644cc480aac7c1cc8d2940cfaf0b447ee2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
