{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import nopdb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.util.plotting import plot_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating base model...\n",
      "creating upsample model...\n",
      "downloading base checkpoint...\n",
      "downloading upsampler checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('creating base model...')\n",
    "base_name = 'base40M' # use base300M or base1B for better results\n",
    "base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
    "base_model.eval()\n",
    "base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
    "\n",
    "print('creating upsample model...')\n",
    "upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "upsampler_model.eval()\n",
    "upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "\n",
    "print('downloading base checkpoint...')\n",
    "base_model.load_state_dict(load_checkpoint(base_name, device))\n",
    "\n",
    "print('downloading upsampler checkpoint...')\n",
    "upsampler_model.load_state_dict(load_checkpoint('upsample', device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointCloudSampler(\n",
    "    device=device,\n",
    "    models=[base_model, upsampler_model],\n",
    "    diffusions=[base_diffusion, upsampler_diffusion],\n",
    "    num_points=[1024, 4096 - 1024],\n",
    "    aux_channels=['R', 'G', 'B'],\n",
    "    guidance_scale=[3.0, 3.0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5f505216b1427a89a8ee5e521ba728",
       "model_id": "d16e2294c688403caf46c9e0f9f19d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "the xt torch.Size([2, 6, 1024])\n",
      "hey\n",
      "hey\n",
      "the xt torch.Size([2, 6, 3072])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 3072])\n",
      "the xt torch.Size([2, 6, 3072])\n",
      "hey\n",
      "the xt torch.Size([2, 6, 3072])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nopdb\u001b[38;5;241m.\u001b[39mcapture_call(base_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mresblocks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mattn\u001b[38;5;241m.\u001b[39mattention\u001b[38;5;241m.\u001b[39mforward) \u001b[38;5;28;01mas\u001b[39;00m attn_call:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tqdm(sampler\u001b[38;5;241m.\u001b[39msample_batch_progressive(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, model_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(images\u001b[38;5;241m=\u001b[39m[img]))):\n\u001b[1;32m      9\u001b[0m         samples \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/sampler.py:176\u001b[0m, in \u001b[0;36mPointCloudSampler.sample_batch_progressive\u001b[0;34m(self, batch_size, model_kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         internal_batch_size \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    169\u001b[0m     samples_it \u001b[38;5;241m=\u001b[39m diffusion\u001b[38;5;241m.\u001b[39mp_sample_loop_progressive(\n\u001b[1;32m    170\u001b[0m         model,\n\u001b[1;32m    171\u001b[0m         shape\u001b[38;5;241m=\u001b[39m(internal_batch_size, \u001b[38;5;241m*\u001b[39msample_shape[\u001b[38;5;241m1\u001b[39m:]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         clip_denoised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_denoised,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m samples_it:\n\u001b[1;32m    177\u001b[0m     samples \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_xstart\u001b[39m\u001b[38;5;124m\"\u001b[39m][:batch_size]\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_res\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stage_model_kwargs:\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/k_diffusion.py:191\u001b[0m, in \u001b[0;36mkarras_sample_progressive\u001b[0;34m(diffusion, model, shape, steps, clip_denoised, progress, model_kwargs, device, sigma_min, sigma_max, rho, sampler, s_churn, s_tmin, s_tmax, s_noise, guidance_scale)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     guided_denoiser \u001b[38;5;241m=\u001b[39m denoiser\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m sample_fn(\n\u001b[1;32m    192\u001b[0m     guided_denoiser,\n\u001b[1;32m    193\u001b[0m     x_T,\n\u001b[1;32m    194\u001b[0m     sigmas,\n\u001b[1;32m    195\u001b[0m     progress\u001b[38;5;241m=\u001b[39mprogress,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampler_args,\n\u001b[1;32m    197\u001b[0m ):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhey\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(diffusion, GaussianDiffusion):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:56\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 56\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/k_diffusion.py:287\u001b[0m, in \u001b[0;36msample_heun\u001b[0;34m(denoiser, x, sigmas, progress, s_churn, s_tmin, s_tmax, s_noise)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Heun's method\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     x_2 \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m*\u001b[39m dt\n\u001b[0;32m--> 287\u001b[0m     denoised_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdenoiser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     d_2 \u001b[38;5;241m=\u001b[39m to_d(x_2, sigmas[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], denoised_2)\n\u001b[1;32m    289\u001b[0m     d_prime \u001b[38;5;241m=\u001b[39m (d \u001b[38;5;241m+\u001b[39m d_2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/k_diffusion.py:183\u001b[0m, in \u001b[0;36mkarras_sample_progressive.<locals>.guided_denoiser\u001b[0;34m(x_t, sigma)\u001b[0m\n\u001b[1;32m    181\u001b[0m x_t \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([x_t, x_t], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    182\u001b[0m sigma \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([sigma, sigma], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 183\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m \u001b[43mdenoiser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m cond_x_0, uncond_x_0 \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39msplit(x_0, \u001b[38;5;28mlen\u001b[39m(x_0) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    185\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m uncond_x_0 \u001b[38;5;241m+\u001b[39m guidance_scale \u001b[38;5;241m*\u001b[39m (cond_x_0 \u001b[38;5;241m-\u001b[39m uncond_x_0)\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/k_diffusion.py:170\u001b[0m, in \u001b[0;36mkarras_sample_progressive.<locals>.denoiser\u001b[0;34m(x_t, sigma)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoiser\u001b[39m(x_t, sigma):\n\u001b[0;32m--> 170\u001b[0m     _, denoised \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/k_diffusion.py:111\u001b[0m, in \u001b[0;36mGaussianToKarrasDenoiser.denoise\u001b[0;34m(self, x_t, sigmas, clip_denoised, model_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m c_in \u001b[38;5;241m=\u001b[39m append_dims(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (sigmas\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m, x_t\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# C_in [2, 1, 1] same values as t\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# x_t.ndim = 3\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# X_T*C_IN [2, 6, 1024]\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Here: Calls to diffusion block with model\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_xstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/gaussian_diffusion.py:308\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_mean_variance\u001b[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     model_variance \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mexp(model_log_variance)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     min_log \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_into_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_log_variance_clipped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     max_log \u001b[38;5;241m=\u001b[39m _extract_into_tensor(np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbetas), t, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# The model_var_values is [-1, 1] for [min_var, max_var].\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CV2/Project/point_e_team10/point_e/diffusion/gaussian_diffusion.py:1035\u001b[0m, in \u001b[0;36m_extract_into_tensor\u001b[0;34m(arr, timesteps, broadcast_shape)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_into_tensor\u001b[39m(arr, timesteps, broadcast_shape):\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m    Extract values from a 1-D numpy array for a batch of indices.\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1035\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[timesteps]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(broadcast_shape):\n\u001b[1;32m   1037\u001b[0m         res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load an image to condition on.\n",
    "img = Image.open('example_data/cube_stack.jpg')\n",
    "\n",
    "# Produce a sample from the model.\n",
    "samples = None\n",
    "with nopdb.capture_calls(base_model.backbone.resblocks[-1].attn.attention.forward) as attn_call:\n",
    "    for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(images=[img]))):\n",
    "\n",
    "        samples = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_heads_to_batch_dim(tensor):\n",
    "        batch_size, seq_len, heads, dim = tensor.shape\n",
    "        tensor = tensor.permute(0, 2, 1, 3).reshape(batch_size * heads, seq_len, dim)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "dict_keys(['self', 'qkv', 'bs', 'n_ctx', 'width', 'attn_ch', 'scale', 'q', 'k', 'v', 'weight', 'wdtype'])\n",
      "torch.Size([2, 1281, 8, 64])\n",
      "torch.Size([2, 1281, 8, 64])\n",
      "torch.Size([16, 1281, 64])\n",
      "torch.Size([16, 1281, 64])\n"
     ]
    }
   ],
   "source": [
    "print(len(attn_call))\n",
    "print(attn_call[0].locals.keys())\n",
    "# print(attn_call[0].locals['weight'].shape)\n",
    "# print(attn_call.locals['x'].shape)\n",
    "\n",
    "# attentions = attn_call[0].locals['weight'][0, :, 0, 257:].reshape(8, -1)\n",
    "# print(attentions.shape)\n",
    "# print(attn_call[0].locals['qkv'].shape)\n",
    "\n",
    "print(attn_call[0].locals['q'].shape)\n",
    "print(attn_call[0].locals['k'].shape)\n",
    "new_q = reshape_heads_to_batch_dim(attn_call[0].locals['q'])\n",
    "new_k = reshape_heads_to_batch_dim(attn_call[0].locals['k'])\n",
    "\n",
    "print(new_q.shape)\n",
    "print(new_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "scale = 1 / math.sqrt(math.sqrt(attn_call[0].locals['attn_ch']))\n",
    "\n",
    "#Manually extract the query and key tensors and combine them as in transformer module, to obtain the attention map.\n",
    "new_q = reshape_heads_to_batch_dim(attn_call[0].locals['q'])\n",
    "new_k = reshape_heads_to_batch_dim(attn_call[0].locals['k'])\n",
    "attention_scores = torch.einsum(\"b i d, b j d -> b i j\", new_q, new_k) * scale\n",
    "\n",
    "attention_probs = attention_scores.softmax(dim=-1)\n",
    "print(attention_probs.shape)\n",
    "''' \n",
    "Shape is batch*heads, 1281,1281. Now perhaps we can slice the 1st dimension starting \n",
    "after all the extra tokens to get the attentions of the point cloud. So smth like\n",
    "[:,257:,258:] will give the attention of all points that the first point attends to.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = sampler.output_to_point_clouds(samples)[0]\n",
    "fig = plot_point_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b270b0f43bc427bcab7703c037711644cc480aac7c1cc8d2940cfaf0b447ee2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
