{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import imageio\n",
    "import importlib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import nopdb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.util.plotting import plot_point_cloud\n",
    "from point_e.util.plotting import plot_attention_cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('creating base model...')\n",
    "base_name = 'base40M' # use base300M or base1B for better results\n",
    "base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
    "base_model.eval()\n",
    "base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
    "\n",
    "print('creating upsample model...')\n",
    "upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "upsampler_model.eval()\n",
    "upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "\n",
    "print('downloading base checkpoint...')\n",
    "base_model.load_state_dict(load_checkpoint(base_name, device))\n",
    "\n",
    "print('downloading upsampler checkpoint...')\n",
    "upsampler_model.load_state_dict(load_checkpoint('upsample', device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointCloudSampler(\n",
    "    device=device,\n",
    "    models=[base_model, upsampler_model],\n",
    "    diffusions=[base_diffusion, upsampler_diffusion],\n",
    "    num_points=[1024, 4096 - 1024],\n",
    "    aux_channels=['R', 'G', 'B'],\n",
    "    guidance_scale=[3.0, 3.0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image to condition on.\n",
    "img = Image.open('example_data/cube_stack.jpg')\n",
    "\n",
    "def sample_from_model(breakpoint):\n",
    "    samples = None\n",
    "    k = 0\n",
    "    with nopdb.capture_call(base_model.backbone.resblocks[-1].attn.attention.forward) as attn_call:\n",
    "        for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(images=[img]))):\n",
    "            if x.shape[2] == 1024:\n",
    "                samples = x\n",
    "                if k == breakpoint:\n",
    "                    break\n",
    "                k += 1\n",
    "            else:\n",
    "                break\n",
    "    scale = 1 / math.sqrt(math.sqrt(attn_call.locals['attn_ch']))\n",
    "\n",
    "    new_q = attn_call.locals['q'][0].permute(1,0,2)\n",
    "    new_k = attn_call.locals['k'][0].permute(1,0,2)\n",
    "    #print(new_k.shape)\n",
    "    #print(new_q.shape)\n",
    "\n",
    "    attention_scores = torch.einsum(\"b i d, b j d -> b i j\", new_q, new_k) * scale\n",
    "    attention_probs = attention_scores.softmax(dim=-1)\n",
    "    \n",
    "    # Average across all heads\n",
    "    avg_attn = torch.mean(attention_probs, dim = 0)\n",
    "    \n",
    "    # Est. self attention\n",
    "    pc_self_attn = avg_attn[257:, 257:]\n",
    "    \n",
    "    # Est. cross attention\n",
    "    pc_cross_attn = avg_attn[:257, 257:]\n",
    "\n",
    "    pc_self_attn = pc_self_attn.cpu()\n",
    "    pc_cross_attn = pc_cross_attn.cpu()\n",
    "    avg_attn = avg_attn.cpu()\n",
    "    \n",
    "    return pc_self_attn, pc_cross_attn, avg_attn, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoints = [0, 10, 20, 30, 40, 50, 60, -1]\n",
    "time = [0, 1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Attention Map Evaluations\n",
    "\n",
    "## 2.1 Heatmaps\n",
    "\n",
    "## 2.1.1 2-Dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make 2D heatmap\n",
    "\"\"\"\n",
    "\n",
    "frames = []\n",
    "\n",
    "for k in breakpoints:\n",
    "    pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(k)\n",
    "    \n",
    "    ax = sns.heatmap(pc_self_attn, cmap = 'rocket_r')\n",
    "    plt.title('itterations = ' + str(k))\n",
    "    plt.savefig('Figures/Self_attention/' +str(k) + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    ax = sns.heatmap(pc_cross_attn, cmap = 'rocket_r')\n",
    "    plt.title('itterations = ' + str(k))\n",
    "    plt.savefig('Figures/Cross_attention/' +str(k) + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    ax = sns.heatmap(avg_attn, cmap = 'rocket_r')\n",
    "    plt.title('itterations = ' + str(k))\n",
    "    plt.savefig('Figures/Full_attention/' +str(k) + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make Gif\n",
    "\"\"\"\n",
    "\n",
    "images = ['Figures/Full_attention/' + str(k) + '.png' for k in breakpoints]\n",
    "frames = []\n",
    "for t in time:\n",
    "    image = imageio.v2.imread(images[t])\n",
    "    frames.append(image)\n",
    "    \n",
    "imageio.mimsave('Figures/Full_attention/full_attention.gif', frames, fps = 0.5)\n",
    "\n",
    "images = ['Figures/Self_attention/' + str(k) + '.png' for k in breakpoints]\n",
    "frames = []\n",
    "for t in time:\n",
    "    image = imageio.v2.imread(images[t])\n",
    "    frames.append(image)\n",
    "    \n",
    "imageio.mimsave('Figures/Self_attention/self_attention.gif', frames, fps = 0.5)\n",
    "\n",
    "images = ['Figures/Cross_attention/' + str(k) + '.png' for k in breakpoints]\n",
    "frames = []\n",
    "for t in time:\n",
    "    image = imageio.v2.imread(images[t])\n",
    "    frames.append(image)\n",
    "    \n",
    "imageio.mimsave('Figures/Cross_attention/cross_attention.gif', frames, fps = 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 3-Dimensions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import point_e\n",
    "importlib.reload(point_e.util.plotting)\n",
    "from point_e.util.plotting import plot_attention_index\n",
    "\n",
    "frames = []\n",
    "import numpy as np\n",
    "for k in breakpoints:\n",
    "    pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(k)\n",
    "    pc = sampler.output_to_point_clouds(samples)[0]\n",
    "    \n",
    "    fig = plot_attention_index(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)), col = pc_self_attn)\n",
    "    fig.suptitle('iterations = ' + str(k))\n",
    "    plt.savefig('Figures/attention_idx/fig' + str(k) + '.png', bbox_inches='tight')\n",
    "    image = imageio.v2.imread('Figures/attention_idx/fig' + str(k) + '.png')\n",
    "    frames.append(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "imageio.mimsave('Figures/attention_idx/attention_idx.gif', # output gif\n",
    "                frames,          # array of input frames\n",
    "                fps = 0.5)         # optional: frames per second"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Indexbased heatmaps\n",
    "Look at heatmap in spesific index ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i, j = 250, 270\n",
    "pc_self_attn = avg_attn[i:j, i:j]\n",
    "\n",
    "print(pc_self_attn.shape)\n",
    "pc_self_attn = pc_self_attn.cpu()\n",
    "import numpy as np\n",
    "ax = sns.heatmap(pc_self_attn, cmap = 'rocket_r', yticklabels=np.round(np.linspace(i,j,j-i), 0).astype(int), xticklabels=np.round(np.linspace(i,j,j-i).astype(int), 0), vmin = 0, vmax = 0.2)\n",
    "#plt.show()\n",
    "plt.savefig('Figures/zoom.png', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Spectra plots\n",
    "\n",
    "Plot spectra of attention in index i from all components j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(65)\n",
    "fig,a =  plt.subplots(2,2)\n",
    "print(pc_self_attn.shape)\n",
    "plt.suptitle('Last itteration at downsampled diffusion (65)')\n",
    "a[0][0].plot(pc_self_attn[0])\n",
    "a[0][0].set_title('i = 0')\n",
    "a[0][1].plot(pc_self_attn[500])\n",
    "a[0][1].set_title('i = 500')\n",
    "a[1][0].plot(pc_self_attn[1000])\n",
    "a[1][0].set_title('i = 1000')\n",
    "a[1][1].plot(pc_self_attn[-1])\n",
    "a[1][1].set_title('i = 1024')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "#plt.savefig('Mid_Itteration.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = [0, 1, 2]\n",
    "frames = []\n",
    "images = ['First_Itteration.png', 'Mid_Itteration.png', 'Last_Itteration.png']\n",
    "for t in time:\n",
    "    image = imageio.v2.imread(images[t])\n",
    "    frames.append(image)\n",
    "    \n",
    "imageio.mimsave('evolve.gif', # output gif\n",
    "                frames,          # array of input frames\n",
    "                fps = 0.5)         # optional: frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = sampler.output_to_point_clouds(samples)[0]\n",
    "fig = plot_point_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)))\n",
    "\n",
    "plt.savefig('fig.png', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Code to plot colored attention clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(point_e.util.plotting)\n",
    "from point_e.util.plotting import plot_attention_cloud\n",
    "\n",
    "frames = []\n",
    "import numpy as np\n",
    "for k in breakpoints:\n",
    "    pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(k)\n",
    "    pc = sampler.output_to_point_clouds(samples)[0]\n",
    "    c = np.diagonal(pc_self_attn)\n",
    "    print(type(c))\n",
    "    fig = plot_attention_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)), col = c)\n",
    "    fig.suptitle('iterations = ' + str(k))\n",
    "    plt.savefig('Figures/Diffusion_gif_2/fig' + str(k) + '.png', bbox_inches='tight')\n",
    "    image = imageio.v2.imread('Figures/Diffusion_gif_2/fig' + str(k) + '.png')\n",
    "    frames.append(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "imageio.mimsave('Figures/Diffusion_gif_2/Diffusion_at_scale.gif', # output gif\n",
    "                frames,          # array of input frames\n",
    "                fps = 0.5)         # optional: frames per second"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Point Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoints = [i*2 for i in range(0,33)]\n",
    "print(breakpoints)\n",
    "time = [i for i in range(len(breakpoints))]\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(point_e.util.plotting)\n",
    "from point_e.util.plotting import plot_attention_cloud\n",
    "\n",
    "frames = []\n",
    "import numpy as np\n",
    "for k in breakpoints:\n",
    "    pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(k)\n",
    "    pc = sampler.output_to_point_clouds(samples)[0]\n",
    "    c = np.zeros(1024)\n",
    "    #c[500] = 1\n",
    "    fig = plot_attention_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)), col = c, alpha_val = 0.2, track_idx = 500)\n",
    "    fig.suptitle('iterations = ' + str(k))\n",
    "    plt.savefig('Figures/Point_tracker/fig' + str(k) + '.png', bbox_inches='tight')\n",
    "    image = imageio.v2.imread('Figures/Point_tracker/fig' + str(k) + '.png')\n",
    "    frames.append(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "imageio.mimsave('Figures/Point_tracker/Diffusion_point_tracker.gif', # output gif\n",
    "                frames,          # array of input frames\n",
    "                fps = 2)         # optional: frames per second"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Max attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(point_e.util.plotting)\n",
    "from point_e.util.plotting import plot_attention_cloud\n",
    "\n",
    "frames = []\n",
    "import numpy as np\n",
    "for k in breakpoints:\n",
    "    pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(k)\n",
    "    pc = sampler.output_to_point_clouds(samples)[0]\n",
    "    \n",
    "    c = torch.max(pc_self_attn, dim = 1)[0]\n",
    "    print(c)\n",
    "    fig = plot_attention_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)), col = c)\n",
    "    fig.suptitle('iterations = ' + str(k))\n",
    "    plt.savefig('Figures/Max_attention/fig' + str(k) + '.png', bbox_inches='tight')\n",
    "    image = imageio.v2.imread('Figures/Max_attention/fig' + str(k) + '.png')\n",
    "    frames.append(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "imageio.mimsave('Figures/Max_attention/Diffusion_at_max.gif', # output gif\n",
    "                frames,          # array of input frames\n",
    "                fps = 0.5)         # optional: frames per second"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Disco boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(point_e.util.plotting)\n",
    "from point_e.util.plotting import plot_attention_cloud\n",
    "\n",
    "pc_self_attn, pc_cross_attn, avg_attn, samples = sample_from_model(65)\n",
    "pc = sampler.output_to_point_clouds(samples)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = np.ones(pc_self_attn.shape, dtype=bool)\n",
    "np.fill_diagonal(mask, 0)\n",
    "print(mask)\n",
    "#max_value = a[mask].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_off_diagonal_mask(off_element):\n",
    "    mask = np.zeros_like(pc_self_attn)\n",
    "    k = 0\n",
    "    for i in range(len(mask)):\n",
    "        try:\n",
    "            mask[i+off_element, i] = 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "    for i in reversed(range(off_element)):\n",
    "        mask[k, -(i+1)] = 1\n",
    "        k += 1\n",
    "    return np.sum(mask*pc_self_attn.numpy(), axis = 1)\n",
    "\n",
    "\n",
    "print(build_off_diagonal_mask(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood = np.arange(-100, 100, 5)\n",
    "print(neighbourhood)\n",
    "time = [i for i in range(len(neighbourhood))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(point_e.util.plotting)\n",
    "from point_e.util.plotting import plot_attention_cloud\n",
    "\n",
    "frames = []\n",
    "import numpy as np\n",
    "for k in neighbourhood:\n",
    "    c = build_off_diagonal_mask(k)\n",
    "    #c = np.diag(pc_self_attn)\n",
    "    #c[500] = 1\n",
    "    fig = plot_attention_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)), col = c, alpha_val = 0.5)\n",
    "    fig.suptitle('off_diagonal_element = ' + str(k))\n",
    "    plt.savefig('Figures/Disco_box/fig' + str(k) + '.png', bbox_inches='tight')\n",
    "    image = imageio.v2.imread('Figures/Disco_box/fig' + str(k) + '.png')\n",
    "    frames.append(image)\n",
    "    \n",
    "    \n",
    "    \n",
    "imageio.mimsave('Figures/Disco_box/Diffusion_disco.gif', # output gif\n",
    "                frames,          # array of input frames\n",
    "                fps = 0.5)         # optional: frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b270b0f43bc427bcab7703c037711644cc480aac7c1cc8d2940cfaf0b447ee2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
